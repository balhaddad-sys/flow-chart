name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  FIREBASE_PROJECT_ID: medq-a6cc6
  NODE_VERSION: '22'

# Only one deploy pipeline runs at a time; queues the next run.
# cancel-in-progress is FALSE because cancelling a CI run does NOT cancel
# the GCP operations it spawned, leaving orphaned "in progress" operations
# that block ALL subsequent deploys with "operation already in progress".
concurrency:
  group: firebase-deploy
  cancel-in-progress: false

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: |
            functions/package-lock.json
            medq-web/package-lock.json

      # ── Next.js ──────────────────────────────────────
      - name: Install Next.js dependencies
        run: cd medq-web && npm ci

      - name: Lint Next.js
        run: cd medq-web && npx next lint

      - name: Run Next.js tests
        run: cd medq-web && npm test -- --runInBand

      - name: Build Next.js
        run: cd medq-web && npx next build
        env:
          NEXT_PUBLIC_FIREBASE_API_KEY: ${{ secrets.NEXT_PUBLIC_FIREBASE_API_KEY }}
          NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN: ${{ secrets.NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN }}
          NEXT_PUBLIC_FIREBASE_PROJECT_ID: ${{ secrets.NEXT_PUBLIC_FIREBASE_PROJECT_ID }}
          NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET: ${{ secrets.NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET }}
          NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID: ${{ secrets.NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID }}
          NEXT_PUBLIC_FIREBASE_APP_ID: ${{ secrets.NEXT_PUBLIC_FIREBASE_APP_ID }}
          NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID: ${{ secrets.NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID }}

      # ── Cloud Functions ──────────────────────────────
      - name: Install Cloud Functions dependencies
        run: cd functions && npm ci

      - name: Run Cloud Functions tests
        run: cd functions && npm test

  deploy-functions:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: functions/package-lock.json

      - name: Install Firebase CLI
        run: npm install -g firebase-tools@latest

      - name: Install Cloud Functions dependencies
        run: cd functions && npm ci

      - name: Authenticate to Google Cloud
        shell: bash
        env:
          SA_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
        run: |
          # Write credentials file
          SA_FILE="${HOME}/sa-key.json"
          printf '%s' "$SA_JSON" > "$SA_FILE"

          # Validate JSON and print service account email for diagnostics
          python3 -c "
          import json, sys
          with open('${SA_FILE}') as f:
              d = json.load(f)
          print('SA email:', d.get('client_email','MISSING'))
          print('Project:  ', d.get('project_id','MISSING'))
          print('Key type: ', d.get('type','MISSING'))
          "

          # Activate via gcloud so firebase-tools picks up credentials from ADC
          gcloud auth activate-service-account \
            --key-file="${SA_FILE}" \
            --project="${FIREBASE_PROJECT_ID}"

          # Belt-and-suspenders: also set GOOGLE_APPLICATION_CREDENTIALS
          echo "GOOGLE_APPLICATION_CREDENTIALS=${SA_FILE}" >> "$GITHUB_ENV"
          echo "SA_FILE=${SA_FILE}"                        >> "$GITHUB_ENV"

      - name: Deploy Firestore indexes/rules and Storage rules
        run: |
          firebase deploy \
            --only firestore,storage \
            --project "${FIREBASE_PROJECT_ID}" \
            --force

      - name: Strip predeploy hook (tests already passed in test job)
        run: |
          python3 - <<'PYEOF'
          import json
          with open("firebase.json") as f:
              cfg = json.load(f)
          for fn in cfg.get("functions", []):
              fn.pop("predeploy", None)
          with open("firebase.json", "w") as f:
              json.dump(cfg, f, indent=2)
          print("Predeploy hook removed.")
          PYEOF

      # ── Fix: ensure gcf-artifacts Artifact Registry repo exists ─────────────
      # Cloud Build pushes function container images to gcf-artifacts.
      # If the repo was deleted or never created, Cloud Build fails with
      # code=13, message=None (no informative error). Create it if missing.
      - name: Fix Artifact Registry permissions for Cloud Functions
        shell: bash
        run: |
          PROJECT_NUMBER=$(gcloud projects describe "${FIREBASE_PROJECT_ID}" \
            --format="value(projectNumber)")
          echo "Project number: ${PROJECT_NUMBER}"
          CF_SERVICE_AGENT="service-${PROJECT_NUMBER}@gcf-admin-robot.iam.gserviceaccount.com"
          CB_COMPUTE_SA="${PROJECT_NUMBER}-compute@developer.gserviceaccount.com"

          echo "=== Checking gcf-artifacts repository ==="
          gcloud artifacts repositories describe gcf-artifacts \
            --project="${FIREBASE_PROJECT_ID}" \
            --location=us-central1 2>&1 || true

          echo "=== Granting ALL required SAs access to gcf-artifacts ==="

          # Reader access for all runtime/service SAs
          for SA in \
            "${CB_COMPUTE_SA}" \
            "${FIREBASE_PROJECT_ID}@appspot.gserviceaccount.com" \
            "${CF_SERVICE_AGENT}" \
            "service-${PROJECT_NUMBER}@serverless-robot-prod.iam.gserviceaccount.com"; do
            echo "--- Granting reader to ${SA} ---"
            gcloud artifacts repositories add-iam-policy-binding gcf-artifacts \
              --project="${FIREBASE_PROJECT_ID}" \
              --location=us-central1 \
              --member="serviceAccount:${SA}" \
              --role="roles/artifactregistry.reader" 2>&1 || true
          done

          # Writer access for build SAs
          for SA in \
            "${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" \
            "${CB_COMPUTE_SA}"; do
            echo "--- Granting writer to ${SA} ---"
            gcloud artifacts repositories add-iam-policy-binding gcf-artifacts \
              --project="${FIREBASE_PROJECT_ID}" \
              --location=us-central1 \
              --member="serviceAccount:${SA}" \
              --role="roles/artifactregistry.writer" 2>&1 || true
          done

          echo "=== Final IAM policy on gcf-artifacts ==="
          gcloud artifacts repositories get-iam-policy gcf-artifacts \
            --project="${FIREBASE_PROJECT_ID}" \
            --location=us-central1 2>&1 || true

          # ── Project-level builder roles for compute SA ──────────────────────
          # GCP changed the default Cloud Build SA — the compute SA now needs
          # explicit Cloud Build + Cloud Run builder roles at the project level.
          echo "=== Granting project-level builder roles to ${CB_COMPUTE_SA} ==="

          gcloud projects add-iam-policy-binding "${FIREBASE_PROJECT_ID}" \
            --member="serviceAccount:${CB_COMPUTE_SA}" \
            --role="roles/cloudbuild.builds.builder" \
            --condition=None 2>&1 | tail -3 || true

          gcloud projects add-iam-policy-binding "${FIREBASE_PROJECT_ID}" \
            --member="serviceAccount:${CB_COMPUTE_SA}" \
            --role="roles/run.builder" \
            --condition=None 2>&1 | tail -3 || true

          # Required for Cloud Functions control plane operations.
          echo "=== Ensuring Cloud Functions service agent role ==="
          gcloud projects add-iam-policy-binding "${FIREBASE_PROJECT_ID}" \
            --member="serviceAccount:${CF_SERVICE_AGENT}" \
            --role="roles/cloudfunctions.serviceAgent" \
            --condition=None 2>&1 | tail -3 || true

          echo "=== Project-level builder roles granted ==="

      # ── Wait for ALL stuck operations to clear ──────────────────────────────
      # Previous CI runs (cancelled by concurrency: cancel-in-progress) left
      # orphaned GCP operations that block all deploy/delete/update actions.
      # Uses the Cloud Functions REST API (gcloud doesn't have operations list).
      - name: Wait for all in-flight Cloud Functions operations to clear
        shell: bash
        run: |
          TOKEN=$(gcloud auth print-access-token)
          API="https://cloudfunctions.googleapis.com/v1"
          LOCATION="projects/${FIREBASE_PROJECT_ID}/locations/us-central1"
          max_wait=600
          elapsed=0
          poll=15

          while true; do
            response=$(curl -s -H "Authorization: Bearer ${TOKEN}" \
              "${API}/${LOCATION}/operations?filter=done%3Dfalse")

            count=$(echo "$response" | python3 -c "
          import sys, json
          try:
              data = json.load(sys.stdin)
              ops = data.get('operations', [])
              print(len(ops))
              for op in ops[:5]:
                  name = op.get('metadata', {}).get('target', op.get('name', 'unknown'))
                  print(f'  in-flight: {name}', file=sys.stderr)
          except:
              print('0')
          " 2>&1)

            echo "${count}"
            active=$(echo "$count" | head -1)

            if [ "$active" = "0" ]; then
              echo "No in-flight operations. Safe to deploy."
              break
            fi

            echo "Waiting for ${active} in-flight operations to clear... (${elapsed}s/${max_wait}s)"

            if [ "$elapsed" -ge "$max_wait" ]; then
              echo "Timed out waiting. Dumping stuck operations:"
              echo "$response" | python3 -m json.tool 2>/dev/null || echo "$response"
              echo ""
              echo "These operations were likely orphaned by cancelled CI runs."
              echo "They should auto-expire. Wait ~10 min and re-run the pipeline."
              exit 1
            fi

            sleep "$poll"
            elapsed=$((elapsed + poll))
          done

      - name: Preflight Cloud Functions control-plane checks
        shell: bash
        run: |
          PROJECT_NUMBER=$(gcloud projects describe "${FIREBASE_PROJECT_ID}" --format="value(projectNumber)")
          echo "Project number: ${PROJECT_NUMBER}"

          echo "--- Service account existence checks ---"
          for SA in \
            "${PROJECT_NUMBER}-compute@developer.gserviceaccount.com" \
            "${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" \
            "${FIREBASE_PROJECT_ID}@appspot.gserviceaccount.com" \
            "service-${PROJECT_NUMBER}@gcf-admin-robot.iam.gserviceaccount.com"; do
            echo "Checking SA: ${SA}"
            gcloud iam service-accounts describe "${SA}" \
              --project "${FIREBASE_PROJECT_ID}" \
              --format="value(email)" 2>&1 || true
          done

          echo "--- Org policy hints (if allowed) ---"
          gcloud resource-manager org-policies describe constraints/cloudfunctions.requireV2 \
            --project "${FIREBASE_PROJECT_ID}" 2>&1 || true
          gcloud resource-manager org-policies describe constraints/gcp.resourceLocations \
            --project "${FIREBASE_PROJECT_ID}" 2>&1 || true

      # ── Write helper script for parsing Cloud Functions operations ────────
      - name: Write operations parser script
        shell: python3 {0}
        run: |
          script = '''\
          import json, sys
          try:
              data = json.load(sys.stdin)
          except Exception as e:
              print(f"Failed to parse operations JSON: {e}")
              raise SystemExit(0)
          ops = data.get("operations", [])
          failed = [op for op in ops if op.get("done") and op.get("error")]
          def op_ts(op):
              md = op.get("metadata", {})
              return md.get("updateTime") or md.get("insertTime") or ""
          failed.sort(key=op_ts, reverse=True)
          if not failed:
              print("No failed operations returned.")
              raise SystemExit(0)
          for op in failed[:15]:
              md = op.get("metadata", {})
              err = op.get("error", {})
              print(f"time={op_ts(op)}")
              print(f"target={md.get('target')}")
              print(f"type={md.get('type')}")
              print(f"code={err.get('code')} message={err.get('message')}")
              details = err.get("details", [])
              if details:
                  print(f"details[0]={details[0]}")
              print("---")
          '''
          import textwrap
          with open("/tmp/parse_ops.py", "w") as f:
              f.write(textwrap.dedent(script))
          print("Wrote /tmp/parse_ops.py")

      # ── Deploy all functions in 4 batches with retries ──────────────────────
      # No set -euo pipefail — we handle errors explicitly via retry logic.
      - name: Deploy functions in 4 batches (with retries)
        shell: bash
        run: |
          echo "firebase-tools version: $(firebase --version)"
          echo "gcloud version: $(gcloud --version | head -1)"

          print_audit_errors() {
            echo "--- Recent Cloud Functions audit errors (Update/Create) ---"
            gcloud logging read \
              'resource.type="cloud_function" AND protoPayload.serviceName="cloudfunctions.googleapis.com" AND (protoPayload.methodName="google.cloud.functions.v1.CloudFunctionsService.UpdateFunction" OR protoPayload.methodName="google.cloud.functions.v1.CloudFunctionsService.CreateFunction") AND severity>=ERROR' \
              --project "${FIREBASE_PROJECT_ID}" \
              --freshness="60m" \
              --limit=20 \
              --format='table(timestamp,protoPayload.methodName,protoPayload.resourceName,protoPayload.status.code,protoPayload.status.message)' 2>&1 || true
            echo "--- Recent Cloud Functions operations errors ---"
            gcloud logging read \
              'protoPayload.serviceName="cloudfunctions.googleapis.com" AND severity>=ERROR' \
              --project "${FIREBASE_PROJECT_ID}" \
              --freshness="60m" \
              --limit=20 \
              --format='table(timestamp,resource.type,protoPayload.methodName,protoPayload.resourceName,protoPayload.status.code,protoPayload.status.message)' 2>&1 || true
          }

          print_cf_operation_errors() {
            echo "--- Cloud Functions operations API (recent failed ops) ---"
            TOKEN=$(gcloud auth print-access-token)
            curl -s -H "Authorization: Bearer ${TOKEN}" \
              "https://cloudfunctions.googleapis.com/v1/projects/${FIREBASE_PROJECT_ID}/locations/us-central1/operations?pageSize=100" \
              | python3 /tmp/parse_ops.py || true
          }

          deploy_batch() {
            local label="$1"
            local only_targets="$2"
            local max_attempts=3
            local attempt=1

            echo ""
            echo "========================================="
            echo "  ${label}"
            echo "========================================="

            while true; do
              echo "[${label}] Attempt ${attempt}/${max_attempts}..."
              if firebase deploy \
                  --only "${only_targets}" \
                  --project "${FIREBASE_PROJECT_ID}" \
                  --force \
                  --non-interactive \
                  --debug > /tmp/deploy.log 2>&1; then
                echo "[${label}] SUCCESS"
                tail -20 /tmp/deploy.log
                return 0
              fi

              echo "[${label}] FAILED — debug output (base64 to bypass masking):"
              tail -80 /tmp/deploy.log | base64
              print_audit_errors
              print_cf_operation_errors
              echo "[${label}] FAILED (attempt ${attempt}/${max_attempts})"

              if [ "${attempt}" -ge "${max_attempts}" ]; then
                echo "[${label}] Giving up after ${max_attempts} attempts."
                return 1
              fi

              local wait_sec=$((attempt * 45))
              echo "[${label}] Waiting ${wait_sec}s before retry..."
              sleep "${wait_sec}"
              attempt=$((attempt + 1))
            done
          }

          failed=0

          # ── Canary: deploy healthCheck alone (no secrets) to test infra ────
          echo ""
          echo "========================================="
          echo "  Canary: healthCheck (no secrets)"
          echo "========================================="
          if firebase deploy \
              --only "functions:healthCheck" \
              --project "${FIREBASE_PROJECT_ID}" \
              --force \
              --non-interactive \
              --debug > /tmp/canary.log 2>&1; then
            echo "[Canary] SUCCESS — infrastructure is healthy"
            tail -10 /tmp/canary.log
          else
            echo "[Canary] FAILED — base64 output:"
            tail -80 /tmp/canary.log | base64
            echo ""
            echo "--- Cloud Build logs for canary ---"
            gcloud builds list --project "${FIREBASE_PROJECT_ID}" --limit=3 \
              --format="table(id,status,createTime,source.storageSource.object)" 2>&1 || true
            echo ""
            echo "--- Checking Secret Manager access for appspot SA ---"
            gcloud secrets list --project "${FIREBASE_PROJECT_ID}" 2>&1 || true
            echo ""
            echo "--- Checking compute SA IAM ---"
            PROJECT_NUMBER=$(gcloud projects describe "${FIREBASE_PROJECT_ID}" --format="value(projectNumber)")
            gcloud projects get-iam-policy "${FIREBASE_PROJECT_ID}" \
              --flatten="bindings[].members" \
              --filter="bindings.members:${PROJECT_NUMBER}-compute@developer.gserviceaccount.com" \
              --format="table(bindings.role)" 2>&1 || true
            echo ""
            print_audit_errors
            echo ""
            echo "=== CANARY FAILED — healthCheck has no secrets, this is a GCP infra issue ==="
            echo "=== File a GCP support ticket with project medq-a6cc6, region us-central1 ==="
            exit 1
          fi

          deploy_batch "Batch 1/4" "functions:processDocumentBatch,functions:processUploadedFile,functions:deleteFile,functions:processSection,functions:generateSectionSummary,functions:sendChatMessage,functions:exploreQuiz,functions:processQuestionBackfillJob" || failed=1

          if [ "$failed" = "1" ]; then
            echo ""
            echo "=== BATCH 1 FAILED — dumping diagnostics ==="
            echo "--- gcloud functions list (current state) ---"
            gcloud functions list --project "${FIREBASE_PROJECT_ID}" --format="table(name.basename(),status,updateTime)" 2>&1 || true
            echo "--- Full deploy log (base64) ---"
            tail -120 /tmp/deploy.log 2>&1 | base64 || true
            print_audit_errors
            print_cf_operation_errors
            exit 1
          fi

          deploy_batch "Batch 2/4" "functions:exploreTopicInsight,functions:deleteUserData,functions:generateSchedule,functions:processExploreBackfillJob,functions:getTutorHelp,functions:reprocessBlueprints,functions:generateQuestions,functions:retryFailedSections" || failed=1
          deploy_batch "Batch 3/4" "functions:generateExamBankQuestions,functions:regenSchedule,functions:catchUp,functions:computeWeakness,functions:finishAssessmentSession,functions:getQuiz,functions:createCourse,functions:submitAssessmentAnswer" || failed=1
          deploy_batch "Batch 4/4" "functions:healthCheck,functions:getAssessmentCatalog,functions:startAssessmentSession,functions:flagQuestion,functions:submitAttempt,functions:runFixPlan,functions:seedSampleDeck,functions:trackActivity" || failed=1

          if [ "$failed" = "1" ]; then
            echo ""
            echo "=== SOME BATCHES FAILED ==="
            print_audit_errors
            print_cf_operation_errors
            exit 1
          fi

          echo ""
          echo "=== ALL 4 BATCHES DEPLOYED SUCCESSFULLY ==="
